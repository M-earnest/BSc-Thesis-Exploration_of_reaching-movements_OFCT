{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for the Viszualization of reconstructed Variance with reduced model parameters\n",
    "\n",
    "### ToDo:\n",
    "    - Documentation\n",
    "    - fix paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno  # handy system and path functions\n",
    "import glob\n",
    "import locale\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import sys  # to get file system encoding\n",
    "import scipy.linalg\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# set Matplotlib parameters globally\n",
    "params = {'legend.fontsize': 14,\n",
    "          'legend.handlelength': 2,\n",
    "         'figure.autolayout': True,\n",
    "         'font.serif' : 'Ubuntu',\n",
    "         'font.family' : 'serif',\n",
    "         'font.monospace' : 'Ubuntu Mono',\n",
    "         'font.size' : 12,\n",
    "         'axes.labelsize' : 16,\n",
    "         'axes.titlesize' : 16,\n",
    "         'xtick.labelsize' : 14,\n",
    "         'ytick.labelsize' : 14,\n",
    "         'figure.titlesize' : 12,\n",
    "         'figure.dpi' : 300}\n",
    "\n",
    "rcParams.update(params)\n",
    "\n",
    "\n",
    "# set Seaborn parameters globally\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ba_analysis_1h_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "marker_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dimensions, event_file, data_file):\n",
    "    '''function to extract and resample movement events,\n",
    "    calculate mean and variance of trahectories for each kinematic dimension\n",
    "    and zero-center trajectories for further use in a SVD\n",
    "    \n",
    "    input: \n",
    "        dimensions = dimensionality of a model; One dimension consists of 1 kinematic dimension + one cartesian dimension\n",
    "                    e.g. full scale model for right arm:\n",
    "                    dimensions = right_hand_marker[:1] + right_wrist + right_lower_arm  + right_upper_arm + right_shoulder \n",
    "        event_file = dataframe containing information on which trials to include\n",
    "        data_file = Dataframe containing all recorded movement data\n",
    "        \n",
    "    output:\n",
    "        model containing zero-centered trajectories for specified dimensions\n",
    "    '''\n",
    "    df_model_a = pd.DataFrame()\n",
    "\n",
    "    for i in dimensions:\n",
    "        i = str(i)\n",
    "\n",
    "        marker = ['marker_'+i+'_x', 'marker_'+i+'_y', 'marker_'+i+'_z']\n",
    "\n",
    "        df_x, df_y, df_z = extract_and_resample(event_file, data_file, marker)\n",
    "        x_mean_dimension, x_variance_dimension, x_df_corrected = get_corrected('x', df_x)\n",
    "        y_mean_dimension, y_variance_dimension, y_df_corrected = get_corrected('y', df_y)\n",
    "        z_mean_dimension, z_variance_dimension, z_df_corrected = get_corrected('z', df_z)\n",
    "\n",
    "        reshaped_df = reshape(x_df_corrected, y_df_corrected, z_df_corrected)\n",
    "\n",
    "        for idx, j in enumerate(reshaped_df.columns):\n",
    "            df_model_a[str(marker[idx])] = reshaped_df[j]\n",
    "    return df_model_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_model(model, parameters):\n",
    "    '''\n",
    "    Function to further specify which dimensions of full scale model created by get_model function \n",
    "    to use for further analysis.\n",
    "    \n",
    "    input:\n",
    "        model = model containing zero-centered trajectories for dimensions of interest\n",
    "        parameters = list of ones and zeros indicating which kinnematich degree of freedom to extract\n",
    "        \n",
    "    output:\n",
    "        list of parameters by which Dataframe containing full scale model can be truncated.\n",
    "    '''\n",
    "    model_parameters = []\n",
    "    for idx, i in enumerate(parameters):  \n",
    "        if i == 1:  # if parameter should be included it is encoded with a 1\n",
    "            model_parameters.append(model.columns[idx])\n",
    "    return model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelComparison(data):\n",
    "    \"\"\"Decompose data with SVD and compute BIC-like approximation to log(P(data|number of primitives))\n",
    "    for each possible number of primitives\n",
    "    returns: variance-accounted-for and log P for each number of synergies\"\"\"\n",
    "    \n",
    "    U,S,VT=np.linalg.svd(data)\n",
    "    \n",
    "    SVT=np.diag(S).dot(VT)\n",
    "    \n",
    "    tot_var=data.var() # this may have to be computed per trial, i.e. as data.var(axis=1).mean()\n",
    "    N=data.size\n",
    "    \n",
    "    VAF=[]\n",
    "    logPD=[]\n",
    "    \n",
    "    for num_prim in range(len(SVT)-2): # -2 to avoid \n",
    "        \n",
    "        sub_u=U[:,:num_prim+1]\n",
    "        sub_svt=SVT[:num_prim+1]\n",
    "        reconstruction=np.dot(sub_u,sub_svt)\n",
    "        \n",
    "        tot_num_df=sub_u.size+sub_svt.size # total number of degrees of freedom in the model\n",
    "        \n",
    "        rec_err_2= ((data-reconstruction)**2).mean()\n",
    "        VAF.append(1.0-rec_err_2/tot_var)\n",
    "        log_likelihood=-N/2*(np.log(2*np.pi)+np.log(rec_err_2)+1)\n",
    "        logPD.append(log_likelihood-0.5*tot_num_df*np.log(N))\n",
    "        fig = plt.figure(figsize=(16,9))\n",
    "        plt.plot(reshaped['x'], color='blue', alpha=0.4)\n",
    "        plt.plot(reconstruction[:,0], color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    return VAF,np.array(logPD), reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(marker_, pos, pos_name, subject_id, path, parameters, data_file, reconstruct_number):\n",
    " \n",
    "    # create subj directory\n",
    "    directory = path+'/graphs/1H/'+subject_id+'/'+pos_name\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    # create directory for ouputs on  velocity\n",
    "    try:\n",
    "        os.makedirs(directory+'/velocity/')\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    # create directory for ouputs on  trajectories\n",
    "    try:\n",
    "        os.makedirs(directory+'/trajectories/')\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    i = marker_ #  marker of specified hand\n",
    "    # define Marker as dictionary with entry for marker in each cartesian dimension\n",
    "    marker_ =['marker_'+i+'_x', 'marker_'+i+'_y', 'marker_'+i+'_z']\n",
    "    \n",
    "\n",
    "    # extract specifics of target postion\n",
    "    box_pos_x = -1*(pos['box_pos_x'][0])\n",
    "    box_pos_z_r = pos['box_pos_z'][0]\n",
    "    box_pos_y_r = pos['box_pos_y'][0]\n",
    "    print('!!!!! Traget Pos: z = '+ str(box_pos_z_r)+ ' ; y = '+ str(box_pos_y_r) )\n",
    "    \n",
    "    # Ectract and resample movement date for trials with specififed target position for specified marker\n",
    "    df_x_r, df_y_r, df_z_r = extract_and_resample(pos, data_file, marker_)\n",
    "    # extract mean trajectory, variance, and zero-centered trajectory for each cartesian dimension\n",
    "    x_mean_dimension_r, x_variance_dimension_r, x_df_corrected_r = get_corrected('x', df_x_r)\n",
    "    y_mean_dimension_r, y_variance_dimension_r, y_df_corrected_r = get_corrected('y', df_y_r)\n",
    "    z_mean_dimension_r, z_variance_dimension_r, z_df_corrected_r = get_corrected('z', df_z_r)\n",
    "\n",
    "    # output extracted data as csvs\n",
    "    df_trajectories = pd.DataFrame()\n",
    "    df_trajectories['x_dim_'+subject_id+'_'+pos_name] = x_mean_dimension_r\n",
    "    df_trajectories['y_dim_'+subject_id+'_'+pos_name] = y_mean_dimension_r\n",
    "    df_trajectories['z_dim_'+subject_id+'_'+pos_name] = z_mean_dimension_r\n",
    "    df_trajectories['x_dim_var_'+subject_id+'_'+pos_name] = x_variance_dimension_r\n",
    "    df_trajectories['y_dim_var_'+subject_id+'_'+pos_name] = y_variance_dimension_r\n",
    "    df_trajectories['z_dim_var_'+subject_id+'_'+pos_name] = z_variance_dimension_r\n",
    "    df_trajectories['box_pos_x'] = box_pos_x\n",
    "    df_trajectories['box_pos_z'] = box_pos_z_r\n",
    "    df_trajectories['box_pos_y'] = box_pos_y_r\n",
    "    df_trajectories.to_csv(path+'/graphs/1H/'+subject_id+'/'+pos_name+'/trajectories/'+pos_name+'_trajectories.csv', index=False, encoding='utf-8')\n",
    "    reshaped_df_r = reshape(x_df_corrected_r, y_df_corrected_r, z_df_corrected_r)\n",
    "    reshaped_df_r.to_csv(path+'/graphs/1H/'+subject_id+'/'+pos_name+'/trajectories/'+pos_name+'_corrected_trajectories.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    # Transform data into np-arrays for easier plotting\n",
    "    x = np.array(x_mean_dimension_r)\n",
    "    z=  np.array(z_mean_dimension_r)\n",
    "    y = np.array(y_mean_dimension_r)\n",
    "    \n",
    "    # lower boundaries of variance\n",
    "    x_l = x - np.array(x_variance_dimension_r)\n",
    "    z_l = z - np.array(z_variance_dimension_r)\n",
    "    y_l  = y - np.array(y_variance_dimension_r)\n",
    "\n",
    "    # upper boundaries of variance\n",
    "    x_u = x + np.array(x_variance_dimension_r)\n",
    "    z_u = z + np.array(z_variance_dimension_r)\n",
    "    y_u  = y + np.array(y_variance_dimension_r)\n",
    "\n",
    "    \n",
    "    ### Plot first mean loading on first vector of U-Matrix\n",
    "    # define dimensionality in marker space    \n",
    "    if subject_id == 'sub-05':\n",
    "        # left_hand_marker = [4,5,6] -> specified in ba_analysis_1h_functions.pyl\n",
    "        dimensions = left_hand_marker[:1] + left_wrist + left_lower_arm  + left_upper_arm + left_shoulder \n",
    "    else:\n",
    "        dimensions = right_hand_marker[:1] + right_wrist + right_lower_arm  + right_upper_arm + right_shoulder \n",
    "#   \n",
    "\n",
    "    # specify Model for dominant arm only\n",
    "    model_r = get_model(dimensions, pos, data_file)\n",
    "    # specify which parameters to extract\n",
    "    model_parameters = specify_model(model_r, parameters)\n",
    "    # build model\n",
    "    model_r = model_r[model_parameters]\n",
    "    \n",
    "#####################################################################################################\n",
    "    \n",
    "    data = np.array(model_r)\n",
    "    U,S,VT=scipy.linalg.svd(data)\n",
    "    \n",
    "    SVT=np.diag(S).dot(VT)\n",
    "    \n",
    "    tot_var=data.var() # this may have to be computed per trial, i.e. as data.var(axis=1).mean()\n",
    "    N=data.size\n",
    "    \n",
    "    VAF=[]\n",
    "    logPD=[]\n",
    "\n",
    "    for num_prim in range(len(SVT)-2): # -2 to avoid \n",
    "        \n",
    "        sub_u=U[:,:reconstruct_number+1]\n",
    "        sub_svt=SVT[:reconstruct_number+1]\n",
    "        reconstruction=np.dot(sub_u,sub_svt)\n",
    "#         df_reconstructed['pc_'+str(counter)] = reconstruction\n",
    "        tot_num_df=sub_u.size+sub_svt.size # total number of degrees of freedom in the model\n",
    "\n",
    "#         fig = plt.figure(figsize=(14,7))\n",
    "#         plt.plot(reconstruction)\n",
    "#         plt.plot(reshaped['x'], color='blue', alpha=0.4)\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "        rec_err_2= ((data-reconstruction)**2).mean()\n",
    "        VAF.append(1.0-rec_err_2/tot_var)\n",
    "        log_likelihood=-N/2*(np.log(2*np.pi)+np.log(rec_err_2)+1)\n",
    "        logPD.append(log_likelihood-0.5*tot_num_df*np.log(N))\n",
    "        \n",
    "    display(model_r.columns)\n",
    "\n",
    "    return model_r,  x_df_corrected_r,  y_df_corrected_r,  z_df_corrected_r, reconstruction\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir_ = '/home/michael/bachelorarbeit/subjects/*'\n",
    "# dir_ = '/home/michael/bachelorarbeit/subjects/sub-09/'\n",
    "\n",
    "path = '/home/michael/bachelorarbeit'\n",
    "list_trajectories_r_x = []\n",
    "list_trajectories_r_y = []\n",
    "list_trajectories_r_z = []\n",
    "list_mean_loadings = []\n",
    "df_velocities = pd.DataFrame()\n",
    "df_mean_loadings = pd.DataFrame()\n",
    "parameters = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "palette = sns.color_palette(\"BuGn\", 9)\n",
    "palette_original = sns.color_palette(\"OrRd\", 10)\n",
    "subjects = []\n",
    "df_reconstructions = pd.DataFrame()\n",
    "df_originals = pd.DataFrame()\n",
    "marker = '7'\n",
    "# marker = '4'\n",
    "\n",
    "df_r1 = pd.DataFrame()\n",
    "subjects_info = pd.DataFrame()\n",
    "# for number_of_primitives in range(13):\n",
    "# reconstruct_number = number_of_primitives+1\n",
    "reconstruct_number = 4\n",
    "for subject in (glob.glob(dir_)):\n",
    "    subject_id = subject.split('/')[5]\n",
    "    print(subject_id)\n",
    "    subjects.append(subject_id)\n",
    "    if subject_id == 'sub-05':  # left-handed\n",
    "        marker = '5'\n",
    "    else:\n",
    "        marker = '7'\n",
    "    for filename in (glob.glob(subject+'/*')):\n",
    "        if filename.split('_')[2] == 'parameters':\n",
    "            subject_parameters = pd.read_csv(filename)\n",
    "            subjects_info = subjects_info.append(subject_parameters)\n",
    "        elif filename.split('-')[3] == '1H' and filename.split('-')[4] == 'events':\n",
    "            event_file_1H = pd.read_csv(filename)\n",
    "        elif filename.split('-')[3] == '1H' and filename.split('-')[4] == 'data':\n",
    "            data_file_1H = pd.read_csv(filename)\n",
    "    r1,r2,r3,m1,m2,m3,l1,l2,l3 = group_by_position(event_file_1H)\n",
    "    positions_list = [r1,r2,r3,m1,m2,m3,l1,l2,l3]\n",
    "    pos_names = ['r1','r2','r3','m1','m2','m3','l1','l2','l3']\n",
    "\n",
    "    for idx, i in enumerate(positions_list):\n",
    "        df_reconstructed = pd.DataFrame()\n",
    "        df_original = pd.DataFrame()\n",
    "        reshaped, df_x, df_y, df_z, reconstruction = plotting(marker, i, pos_names[idx],\n",
    "                                              subject_id, path,parameters,  data_file_1H,\n",
    "                                             reconstruct_number)\n",
    "\n",
    "        for j in range(len(reshaped.columns)):\n",
    "            # RESHAPE ORIGINAL MATRIX\n",
    "            counter = 0\n",
    "            trial_length = 200\n",
    "            concatenated = pd.DataFrame(columns=range(len(reshaped)//trial_length))\n",
    "            reshaped = np.array(reshaped)\n",
    "            for i in range(len(reshaped)//trial_length):\n",
    "\n",
    "                counter +=trial_length\n",
    "                if i == 0:\n",
    "                    concatenated[concatenated.columns[i]] = reshaped[:counter,j]\n",
    "                elif i >0:\n",
    "                    concatenated[concatenated.columns[i]] = reshaped[counter-trial_length:counter,j]\n",
    "\n",
    "            concatenated = concatenated.values\n",
    "            concatenated = np.absolute(concatenated)\n",
    "\n",
    "            # extract mean loading and standarad error of mean\n",
    "            mean_original = []\n",
    "            stdm_original = []\n",
    "            for i in range(trial_length):\n",
    "                mean_original.append(concatenated[i].mean())\n",
    "                stdm_original.append(scipy.stats.sem(concatenated[i]))\n",
    "\n",
    "            mean_original = np.array(mean_original)\n",
    "            df_original[pos_names[idx]+'_'+str(j)] = mean_original\n",
    "\n",
    "            stdm_original = np.array(stdm_original)\n",
    "\n",
    "\n",
    "            # RESHAPE RECONSTRUCTED MATRIX\n",
    "            counter = 0\n",
    "            trial_length = 200\n",
    "            recon_ = pd.DataFrame(columns=range(len(reconstruction)//trial_length))\n",
    "            for i in range(len(reconstruction)//trial_length):\n",
    "\n",
    "                counter +=trial_length\n",
    "                if i == 0:\n",
    "                    recon_[recon_.columns[i]] = reconstruction[:counter,j]\n",
    "                elif i >0:\n",
    "                    recon_[recon_.columns[i]] = reconstruction[counter-trial_length:counter,j]\n",
    "\n",
    "            # transform trial to matrix and transform each point to absolute value            \n",
    "            recon_ = recon_.values\n",
    "            recon_ = np.absolute(recon_)\n",
    "\n",
    "            # extract mean loading and standarad error of mean\n",
    "            mean_recon = []\n",
    "            stdm_recon = []\n",
    "            for i in range(trial_length):\n",
    "                mean_recon.append(recon_[i].mean())\n",
    "                stdm_recon.append(scipy.stats.sem(recon_[i]))\n",
    "\n",
    "            mean_recon = np.array(mean_recon)\n",
    "            df_reconstructed[pos_names[idx]+'_'+str(j)] = mean_recon\n",
    "            stdm_recon = np.array(stdm_recon)\n",
    "\n",
    "        counter_marker_pos = 0\n",
    "        fig = plt.figure(figsize=(15,8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for x in range(len(df_reconstructed.columns)):\n",
    "\n",
    "            if counter_marker_pos > 12:\n",
    "                print('done')\n",
    "            elif counter_marker_pos <= 12:\n",
    "\n",
    "                if counter_marker_pos == 0:\n",
    "                    kin_dim = 'hand'\n",
    "                    colour='navy'\n",
    "                    colour_orig='navy'\n",
    "\n",
    "                elif counter_marker_pos == 3:\n",
    "                    kin_dim = 'wrist'\n",
    "                    colour= 'forestgreen'\n",
    "                    colour_orig='forestgreen'\n",
    "                elif counter_marker_pos == 6:\n",
    "                    kin_dim = 'lower arm'\n",
    "                    colour='darkgoldenrod'\n",
    "                    colour_orig='darkgoldenrod'\n",
    "                elif counter_marker_pos == 9:\n",
    "                    kin_dim = 'upper arm'\n",
    "                    colour='maroon'\n",
    "                    colour_orig='maroon'\n",
    "                elif counter_marker_pos == 12:\n",
    "                    kin_dim = 'shoulder'\n",
    "                    colour='black'\n",
    "                    colour_orig='black'\n",
    "\n",
    "                x = df_reconstructed[df_reconstructed.columns[counter_marker_pos]]\n",
    "                y = df_reconstructed[df_reconstructed.columns[counter_marker_pos+1]]\n",
    "                z = df_reconstructed[df_reconstructed.columns[counter_marker_pos+2]]\n",
    "\n",
    "                x_orig = df_original[df_original.columns[counter_marker_pos]]\n",
    "                y_orig = df_original[df_original.columns[counter_marker_pos+1]]\n",
    "                z_orig = df_original[df_original.columns[counter_marker_pos+2]]\n",
    "\n",
    "                ### PLOT TRAJECTTORIES IN 3D\n",
    "                # right hand\n",
    "                ax.plot(xs=x, ys=z, zs=y,color=colour, label=(kin_dim+'_reconstructed'))\n",
    "                ax.plot(xs=x_orig, ys=z_orig, zs=y_orig, color=colour_orig, label=(kin_dim+'_original'), linestyle=':')\n",
    "\n",
    "                counter_marker_pos += 3\n",
    "        ax.set_xlim(0,.2)\n",
    "        ax.set_zlim(0,.2)\n",
    "        ax.set_ylim(0,.2)\n",
    "        ax.view_init(azim=235)\n",
    "\n",
    "        ax.set_xlabel('x', fontsize=18)\n",
    "        ax.set_ylabel('z', fontsize=18)\n",
    "        ax.set_zlabel('y', fontsize=18)\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(0.06, 1.1),\n",
    "          fancybox=True, shadow=True,  borderaxespad=0.)\n",
    "        plt.title(subject_id+' '+pos_names[idx]+': number of principal components '+str(reconstruct_number), y=-.05)\n",
    "        fig.savefig(path+'/graphs/1H/'+subject_id+'/'+subject_id+'_'+pos_names[idx]+'_pcs_'+str(reconstruct_number)+'_.png')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        df_reconstructions[subject_id+' '+pos_names[idx]+': number of principal components '+str(reconstruct_number)] = mean_recon\n",
    "        df_originals[subject_id+' '+pos_names[idx]+': number of principal components '+str(reconstruct_number)] = mean_original"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
